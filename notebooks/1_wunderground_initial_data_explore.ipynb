{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Weather Underground Hurricane Data\n",
        "\n",
        "-----\n",
        "\n",
        "## Initial Exploration\n",
        "\nA notebook for exploring the hurricane data acquired from the ```src/get_data.py``` script."
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "raw_data_dir = \"../data/raw\"\n",
        "\n",
        "fnames = dict([(x.split('.')[0], os.path.join(raw_data_dir, x)) \n",
        "               for x in os.listdir(raw_data_dir) if x.endswith('.pkl')])\n",
        "\n",
        "raw_data = dict()\n",
        "for k, v in fnames.items():\n",
        "    with open(v, 'rb') as fin:\n",
        "        raw_data[k] = pickle.load(fin)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - Region Data Processing\n",
        "def convert_region_data_helper(x):\n",
        "    \"\"\"Helper function to convert region data\"\"\"\n",
        "    if x == '':\n",
        "        return np.nan\n",
        "    else:\n",
        "        repl_strings = [',', '>', '<', '+']\n",
        "        for rstr in repl_strings:\n",
        "            x = x.replace(rstr, '')\n",
        "        return float(x)\n",
        "\n",
        "def convert_region_data(data_dict):\n",
        "    \"\"\"Function to convert raw Region data\"\"\"\n",
        "    ret = dict()\n",
        "    for k, v in data_dict.items():\n",
        "        ret[k] = convert_region_data_helper(v)\n",
        "    return ret\n",
        "    \n",
        "region_df = None\n",
        "for region, region_data in raw_data['region_data'].items():\n",
        "    conv_data = dict()\n",
        "    for k, v in region_data.items():\n",
        "        conv_data[k] = convert_region_data(v)\n",
        "    t_region_df = pd.DataFrame(conv_data).T\n",
        "    for col in t_region_df.columns:\n",
        "        t_region_df[col] = t_region_df[col].astype(float)\n",
        "    t_region_df.columns = pd.MultiIndex.from_product([[region], t_region_df.columns], \n",
        "                                                     names=['Region', 'Statistic'])\n",
        "    if region_df is None:\n",
        "        region_df = t_region_df.copy()\n",
        "    else:\n",
        "        region_df = pd.concat([region_df, t_region_df], axis=1)\n",
        "\nregion_df.sort_index(inplace=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - Simple plots\n",
        "def plot_helper(data, ax, title=None, ylabel=None):\n",
        "    \"\"\"Helper function to plot data\"\"\"\n",
        "    data.plot(ax=ax)    \n",
        "    if title is not None:\n",
        "        ax.set_title(title)\n",
        "    if ylabel is not None:\n",
        "        ax.set_ylabel(ylabel)\n",
        "    ax.legend()\n",
        "\n",
        "storms = region_df.xs('Storms', axis=1, level='Statistic')\n",
        "hurricanes = region_df.xs('Hurricanes', axis=1, level='Statistic')\n",
        "damages = region_df.xs('Damage', axis=1, level='Statistic')\n",
        "deaths = region_df.xs('Deaths', axis=1, level='Statistic')\n",
        "    \n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, ncols=1, figsize=(12, 12))\n",
        "plot_helper(storms, ax1, ylabel='# of Storms')\n",
        "plot_helper(hurricanes, ax2, ylabel='# of Hurricanes')\n",
        "plot_helper(damages, ax3, ylabel='Damage (Millions USD)')\n",
        "plot_helper(deaths, ax4, ylabel='Deaths')\n",
        "\n",
        "ax1.set_title('Regional Data by Year')\n",
        "ax4.set_xlabel('Date');"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false,
        "outputExpanded": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - Region-Year Data Processing\n",
        "def process_region_year_data_helper(year, k, v):\n",
        "    \"\"\"Helper function to process region-year data\"\"\"\n",
        "    numeric_flds = ['Max Winds', 'Min Pressure', 'Deaths', 'Damage']\n",
        "    if k == 'Storm':\n",
        "        return v\n",
        "    elif k == 'Dates':\n",
        "        spl_dts = v.replace('-', ' ').split(' ')\n",
        "        ret = list()\n",
        "        for dt in spl_dts:\n",
        "            t_dt = dt.strip()\n",
        "            if t_dt == '' or t_dt.startswith('999'):\n",
        "                continue\n",
        "            \n",
        "            sub_spl_dts = t_dt.split('/')\n",
        "            sub_spl_dts[0] = np.mod(int(sub_spl_dts[0]), 13)\n",
        "            if sub_spl_dts[0] == 0:\n",
        "                sub_spl_dts[0] = 1\n",
        "            \n",
        "            str_dts = [\"/{}\".format(x) for x in sub_spl_dts]\n",
        "            \n",
        "            str_dt = str(year)+''.join(str_dts)\n",
        "            try:\n",
        "                t_dtime = datetime.strptime(str_dt, '%Y/%m/%d')\n",
        "            except ValueError as verr:\n",
        "                str_dt = \"{}/{}/1\".format(year, sub_spl_dts[0]+1)\n",
        "                t_dtime = datetime.strptime(str_dt, '%Y/%m/%d') - timedelta(days=1)\n",
        "                \n",
        "            ret.append(t_dtime)\n",
        "        \n",
        "        ret_names = ['Start Date', 'End Date']\n",
        "        ret_dict = dict()\n",
        "        for i in range(len(ret)):\n",
        "            ret_dict[ret_names[i]] = ret[i]\n",
        "                \n",
        "        return ret_dict\n",
        "    \n",
        "    elif k in numeric_flds:\n",
        "        if v == '' or v == 'Unknown':\n",
        "            return np.nan\n",
        "        elif v == 'Minimal':\n",
        "            return 0.\n",
        "        elif v == 'Millions':\n",
        "            return 1000000.\n",
        "        else:\n",
        "            strip_chars = [',', '>', '<', '+']\n",
        "            t_v = v\n",
        "            for x in strip_chars:\n",
        "                t_v = t_v.replace(x, '')\n",
        "            \n",
        "            ret = float(t_v)\n",
        "            if ret == 9999.:\n",
        "                ret = np.nan\n",
        "            return ret\n",
        "       \n",
        "    else:\n",
        "        return v\n",
        "\n",
        "def process_region_year_data(region, year, storm_id, storm_data):\n",
        "    \"\"\"Processes year-data to get storms\"\"\"\n",
        "    unq_id = ''.join([x[0].upper() for x in region.split(' ')])\n",
        "    unq_id += '{}{:02}'.format(year, storm_id)\n",
        "    \n",
        "    ret_data = dict()\n",
        "    ret_data['Region'] = region\n",
        "    for k, v in storm_data.items():\n",
        "        try:\n",
        "            t_ret_data = process_region_year_data_helper(year, k, v)\n",
        "            if isinstance(t_ret_data, dict):\n",
        "                ret_data = {**ret_data, **t_ret_data}\n",
        "            else:\n",
        "                ret_data[k] = t_ret_data\n",
        "        except Exception as ex:\n",
        "            print(k, v)\n",
        "            raise ex\n",
        "    \n",
        "    return unq_id, ret_data\n",
        "\n",
        "storm_year_data = dict()\n",
        "for region, year_data in raw_data['region_year_data'].items():\n",
        "    for yr, data in year_data.items():\n",
        "        for t_storm_id, t_storm_data in data.items():\n",
        "            t_id, t_data = process_region_year_data(region, yr, t_storm_id, t_storm_data)\n",
        "            storm_year_data[t_id] = t_data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storm_year_df = None\n",
        "for k, v in storm_year_data.items():\n",
        "    t_df = pd.DataFrame(v, index=[k])\n",
        "    \n",
        "    if storm_year_df is None:\n",
        "        storm_year_df = t_df\n",
        "    else:\n",
        "        storm_year_df = pd.concat([storm_year_df, t_df], axis=0, sort=False)\n",
        "\n",
        "storm_year_df.index.name = 'StormID'\n",
        "storm_year_df.sort_values('Start Date', axis=0, inplace=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - Max Winds over Time\n",
        "nz_maxwind_filter = (storm_year_df.loc[:, 'Max Winds'] > 0) \\\n",
        "                    & ~np.isnan(storm_year_df.loc[:, 'Max Winds'])\n",
        "max_winds = storm_year_df.where(nz_maxwind_filter).set_index('Start Date') \\\n",
        "                         .loc[:, 'Max Winds']\n",
        "\n",
        "# - Plot\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.gca()\n",
        "\n",
        "max_winds.groupby(max_winds.index.year, axis=0).min().plot(ax=ax, label='Min', \n",
        "                                                           color='green')\n",
        "max_winds.groupby(max_winds.index.year, axis=0).mean().plot(ax=ax, label='Mean')\n",
        "max_winds.groupby(max_winds.index.year, axis=0).max().plot(ax=ax, label='Max', \n",
        "                                                           color='orange')\n",
        "\n",
        "ax.set_title('Average Max Wind Speed by Year')\n",
        "ax.set_ylabel('Max Wind Speed (mph)')\n",
        "ax.set_xlabel('Date')\n",
        "ax.legend();"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_single_track_point(data_dict):\n",
        "    \"\"\"Helper function to process single track data point\"\"\"\n",
        "    key_dt = None\n",
        "    key_tm = None\n",
        "    vals = dict()\n",
        "    \n",
        "    for k, v in data_dict.items():\n",
        "        if k == 'Date':\n",
        "            b_is_numeric = False\n",
        "            try:\n",
        "                _ = int(v[0])\n",
        "                key_dt = datetime.strptime(v, '%m/%d/%Y').date()\n",
        "            except Exception:\n",
        "                key_dt = datetime.strptime(v, '%b/%d/%Y').date()\n",
        "        \n",
        "        elif k == 'Time':\n",
        "            if len(v.split(' ')[0]) > 2:\n",
        "                key_tm = datetime.strptime(v, '%H%M %Z').time()\n",
        "            else:\n",
        "                key_tm = datetime.strptime(v, '%H %Z').time()\n",
        "        \n",
        "        elif k == 'Storm Type':\n",
        "            vals[k] = v\n",
        "        \n",
        "        else:\n",
        "            if v == 'Unknown':\n",
        "                t_v = np.nan\n",
        "            else:\n",
        "                t_v = float(v)\n",
        "            \n",
        "            vals[k] = t_v\n",
        "    \n",
        "    return datetime.combine(key_dt, key_tm), vals\n",
        "\n\n",
        "def process_storm_track_data_points(region, year, storm_id, track_data):\n",
        "    \"\"\"Helper function to process track data points\"\"\"\n",
        "    storm_code = ''.join([x[0] for x in region.upper().split(' ')])\n",
        "    storm_code += '{}{:02d}'.format(year, storm_id)\n",
        "    \n",
        "    ret = dict()\n",
        "    for data_point in track_data:\n",
        "        try:\n",
        "            fmt_date, fmt_data = process_single_track_point(data_point)\n",
        "        except Exception as ex:\n",
        "            print(data_point)\n",
        "            raise ex\n",
        "        ret[fmt_date] = fmt_data\n",
        "    \n",
        "    return storm_code, ret\n",
        "\n\n",
        "track_data = dict()\n",
        "for region, region_data in raw_data['storm_data'].items():\n",
        "    for year, storms in region_data.items():\n",
        "        for storm_id, storm_track_data in storms.items():\n",
        "            t_id, t_data = process_storm_track_data_points(region, year, storm_id, \n",
        "                                                           storm_track_data)\n",
        "            track_data[t_id] = t_data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "hurricanes-env"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "hurricanes-env",
      "language": "python",
      "display_name": "Hurricane Data Env"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}